VisionChef: Smart Fridge Assistant
<div align="center"> <img src="./images/main.jpg" alt="VisionChef Main Interface" width="800"/> <p><em>Main application interface showing detected ingredients and recipe suggestions</em></p> </div>
VisionChef is an intelligent web application that helps you reduce food waste and cook creative meals. It uses AI object detection (YOLOv8) to identify ingredients in your fridge from a photo and suggests recipes based on what you have (via Spoonacular API).

The UI is designed with a premium Samsung One UI aesthetic, featuring clean lines, large squircles, and intuitive interactions.

âœ¨ Features
ğŸ¤– AI Ingredient Detection: Automatically identifies food items in uploaded images using a fine-tuned YOLOv8 model.

ğŸ” Smart Recipe Search: Suggests recipes based on detected ingredients, prioritizing what you already have.

ğŸ“– Detailed Recipe View: View full instructions, missing ingredients, and cook times in a beautiful modal.

ğŸ¨ Samsung One UI Design: Modern, responsive interface with Dark Mode support.

ğŸ§  Custom Training: Includes scripts to merge datasets and fine-tune the model on specific ingredients.

ğŸ“¸ Visual Walkthrough
ğŸ½ï¸ Recipe Discovery Interface
<div align="center"> <img src="./images/main.jpg" alt="Recipe List View" width="600"/> <p><em>Browse recipes with ingredient detection results and cooking metrics</em></p> </div>
ğŸ“‹ Detailed Recipe View
<div align="center"> <div style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;"> <div> <img src="./images/description.jpg" alt="Recipe Description" width="300"/> <p><em>Recipe details with nutrition information</em></p> </div> <div> <img src="./images/descriptionItem.jpg" alt="Recipe Instructions" width="300"/> <p><em>Recipe instructions and required ingredients</em></p> </div> </div> </div>
ğŸ“Š Key Screens
Feature	Screenshot	Description
Main Dashboard	<img src="./images/main.jpg" width="250">	Shows detected ingredients and recipe suggestions
Recipe Details	<img src="./images/description.jpg" width="250">	Displays nutrition info, cooking time, and ratings
Ingredients List	<img src="./images/descriptionItem.jpg" width="250">	Shows required ingredients with checkboxes
ğŸ”„ How It Works
graph TD
    A[ğŸ“¸ Upload Fridge Photo] --> B[ğŸ¤– AI Detection<br/>YOLOv8]
    B --> C[ğŸ“‹ Extract Ingredients]
    C --> D[ğŸ” Query Spoonacular API]
    D --> E[ğŸ³ Display Recipes]
    E --> F[ğŸ“± Samsung One UI Interface]
    F --> G[âœ… User Selects Recipe]
    G --> H[ğŸ‘¨â€ğŸ³ Cook & Enjoy!]
ğŸ“‹ Prerequisites
Before running the project, ensure you have the following installed:

Requirement	Version	Purpose
Python	3.8+	Backend API & AI model
Node.js	16+	Frontend React application
npm	Latest	Package management
Git	Latest	Version control
ğŸ”‘ API Keys
You will need API keys for the following services:

Service	Purpose	Get Key
Spoonacular API	Fetching recipes	Get Key
Roboflow API	Training datasets (optional)	Get Key
ğŸš€ Installation
1. Clone the Repository
bash
git clone https://github.com/Start-Catch-Up/VisionChef.git
cd VisionChef
2. Set Up Images Directory
Ensure your images are in the images folder:

bash
# Verify images are in the correct location
ls images/
# Should show: main.jpg, description.jpg, descriptionItem.jpg
3. Backend Setup
bash
cd backend

# Create and activate virtual environment
python -m venv venv

# Windows
.\venv\Scripts\activate
# Mac/Linux
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
Configure environment variables:

bash
# Copy example environment file
cp .env.example .env
Edit .env file:

env
SPOONACULAR_API_KEY=your_actual_key_here
ROBOFLOW_API_KEY=your_actual_key_here
4. Model Weights (Crucial Step)
<div align="center"> <img src="./images/description.jpg" width="400" alt="AI Model in Action"/> <p><em>AI-powered ingredient detection requires trained weights</em></p> </div>
Download weights from: Google Drive

Create directory:

bash
mkdir -p backend/runs/detect/train/weights
Place files:

text
backend/runs/detect/train/weights/
â”œâ”€â”€ best.pt    # Primary model weights
â””â”€â”€ last.pt    # Backup weights
5. Frontend Setup
bash
cd ../frontend
npm install
ğŸ–¥ï¸ Running the Application
Run both servers in separate terminals:

Terminal 1 - Backend
bash
cd backend
python app.py
# Server: http://localhost:8000
Terminal 2 - Frontend
bash
cd frontend
npm run dev
# Server: http://localhost:5173
<div align="center"> <img src="./images/main.jpg" width="500" alt="Running Application"/> <p><em>Application running with both backend and frontend servers</em></p> </div>
ğŸ§ª Model Training (Optional)
To train your own model:

bash
cd backend
python train.py
This script:

ğŸ“¥ Downloads datasets from Roboflow

ğŸ”„ Merges "Food in Fridge" and "Food Ingredients" datasets

ğŸ‹ï¸â€â™‚ï¸ Trains YOLOv8 model

ğŸ’¾ Saves results to runs/detect/train/

ğŸ“ Project Structure
text
VisionChef/
â”œâ”€â”€ ğŸ“ images/                    # Application screenshots
â”‚   â”œâ”€â”€ main.jpg                 # Main interface
â”‚   â”œâ”€â”€ description.jpg          # Recipe details
â”‚   â””â”€â”€ descriptionItem.jpg      # Ingredients list
â”œâ”€â”€ ğŸ“ backend/
â”‚   â”œâ”€â”€ app.py                   # FastAPI application
â”‚   â”œâ”€â”€ train.py                 # Model training
â”‚   â”œâ”€â”€ evaluate.py              # Model evaluation
â”‚   â”œâ”€â”€ services.py              # YOLO & Spoonacular logic
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â””â”€â”€ ğŸ“ runs/                 # Trained model weights
â”œâ”€â”€ ğŸ“ frontend/
â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx              # React application
â”‚   â”‚   â””â”€â”€ index.css            # Tailwind styles
â”‚   â”œâ”€â”€ tailwind.config.js       # Tailwind config
â”‚   â””â”€â”€ package.json             # Node.js dependencies
â””â”€â”€ README.md                    # This file
ğŸ¯ User Flow
<div align="center"> <img src="./images/main.jpg" alt="User Flow Diagram" width="400" style="border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.15); border: 2px solid #4CAF50;"/> </div>
ğŸ“¸ Capture - Take a photo of your fridge

ğŸ¤– Detect - AI identifies ingredients

ğŸ³ Browse - View matching recipes

ğŸ‘¨â€ğŸ³ Cook - Follow instructions with confidence

ğŸŒ± Reduce Waste - Use what you have efficiently

ğŸ“ Example Usage
python
# Example of how VisionChef processes images
from services import detect_ingredients, get_recipes

# 1. User uploads image
image = "fridge_photo.jpg"

# 2. AI detects ingredients
ingredients = detect_ingredients(image)
# Returns: ["tomatoes", "onion", "eggs", "bacon"]

# 3. Find matching recipes
recipes = get_recipes(ingredients)
# Returns recipes that use detected items
ğŸ› ï¸ Troubleshooting
Issue	Solution
Images not loading	Ensure images are in ./images/ folder
Model weights missing	Download from Google Drive link above
API errors	Check .env file for correct keys
Port conflicts	Change ports in app.py (backend) or vite.config.js (frontend)
ğŸ“„ License
MIT License - see LICENSE file for details.

<div align="center">
ğŸš€ Ready to Reduce Food Waste?
bash
# Start your culinary AI journey
git clone https://github.com/Start-Catch-Up/VisionChef.git
cd VisionChef
# Follow installation steps above
Made with â¤ï¸ by the VisionChef Team
Smart cooking for a sustainable future

<div style="display: flex; justify-content: center; gap: 10px; margin-top: 20px;"> <img src="./images/descriptionItem.jpg" width="150" alt="Ingredients"> <img src="./images/description.jpg" width="150" alt="Recipe"> <img src="./images/main.jpg" width="150" alt="Dashboard"> </div></div>
